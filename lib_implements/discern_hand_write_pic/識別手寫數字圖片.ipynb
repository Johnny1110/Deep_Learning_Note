{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下載手寫數字資料集 mnist\n",
    "(train_imgs, train_labels), (test_imgs, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "資料集的張量維度:  3\n"
     ]
    }
   ],
   "source": [
    "print(\"資料集的張量維度: \", train_imgs.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x23fb79944c8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 這邊取出第4比資料小玩一下\n",
    "\n",
    "\n",
    "digit = train_imgs[4]\n",
    "\n",
    "# [y軸全出取， x軸取 正7 ~ 負7(剛好是28的中間區域)]\n",
    "digit = digit[:, 7:-7]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(digit, cmap=plt.cm.binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_imgs 原本資料 shape:  (60000, 28, 28)\n",
      "train_imgs 原本資料 shape:  (60000, 784)\n",
      "------------------------------------------------------------\n",
      "train_imgs 原本資料 shape:  (10000, 28, 28)\n",
      "train_imgs 原本資料 shape:  (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "# 前置資料整理\n",
    "\n",
    "print(\"train_imgs 原本資料 shape: \", train_imgs.shape)\n",
    "train_imgs = train_imgs.reshape(60000, 28*28)  # 將原本一張圖2維張量 (28, 28) 資料 reshape 成我們想要的(28*28)(60000指6萬張圖)\n",
    "train_imgs = train_imgs.astype('float32') / 255  # 原本資料室 unit8 0~255 之間的灰階，除以 255 把原本 255 變 1 其他全變 0 \n",
    "print(\"train_imgs 整理後資料 shape: \", train_imgs.shape)\n",
    "\n",
    "print('---'*20)\n",
    "\n",
    "print(\"test_imgs 原本資料 shape: \", test_imgs.shape)\n",
    "test_imgs = test_imgs.reshape(10000, 28*28)  # 同理\n",
    "test_imgs = test_imgs.astype('float32') / 255\n",
    "print(\"test_imgs 整理後資料 shape: \", test_imgs.shape)\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "# 對標籤分類，原本是一個純量，分類後彙變成一個 10 維向量 eg. [0. 0. 0. ... 1. 0. 0.]\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立神經網路\n",
    "\n",
    "from keras import models, layers\n",
    "\n",
    "network = models.Sequential()\n",
    "# relu 激勵函數是 max(x, 0) 輸出的 512 個值只放行大於 0 的輸出。\n",
    "network.add(layers.Dense(512, activation='relu', input_shape=(28*28,))) \n",
    "# softmax 可以理解為加權數，這邊代表 1 ~ 10 的機率分布，值在 0~1 之間\n",
    "network.add(layers.Dense(10, activation='softmax')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 編譯神經網路\n",
    "\n",
    "# rmsprop優化器: 規範梯度下降的規則，categorical_crossentropy 是損失函數。\n",
    "network.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "469/469 [==============================] - 5s 10ms/step - loss: 0.2549 - accuracy: 0.9262\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 5s 10ms/step - loss: 0.1038 - accuracy: 0.9698\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 5s 10ms/step - loss: 0.0678 - accuracy: 0.9797\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 5s 10ms/step - loss: 0.0502 - accuracy: 0.9846\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 5s 10ms/step - loss: 0.0375 - accuracy: 0.9891\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23fbe3e18c8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 訓練\n",
    "\n",
    "# epochs 跑 5 runs，一次訓練 128 組圖片\n",
    "network.fit(train_imgs, train_labels, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = network.evaluate(test_imgs, test_labels)\n",
    "print('test_acc: ', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
